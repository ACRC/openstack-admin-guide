<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Hardware Inventory Management &#8212; OpenStack Administration Guide  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=039e1c02" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=b3ba4146"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Ceph Storage" href="ceph_storage.html" />
    <link rel="prev" title="Physical network" href="physical_network.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="hardware-inventory-management">
<h1>Hardware Inventory Management<a class="headerlink" href="#hardware-inventory-management" title="Permalink to this heading">¶</a></h1>
<p>At its lowest level, hardware inventory is managed in the Bifrost service (see <a class="reference internal" href="working_with_kayobe.html#accessing-the-bifrost-service"><span class="std std-ref">Accessing the Bifrost Service</span></a>).</p>
<section id="reconfiguring-control-plane-hardware">
<h2>Reconfiguring Control Plane Hardware<a class="headerlink" href="#reconfiguring-control-plane-hardware" title="Permalink to this heading">¶</a></h2>
<p>If a server’s hardware or firmware configuration is changed, it should be
re-inspected in Bifrost before it is redeployed into service. A single server
can be reinspected like this (for a host named <code class="docutils literal notranslate"><span class="pre">comp0</span></code>):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kayobe# kayobe overcloud hardware inspect --limit comp0</span>
</pre></div>
</div>
</section>
<section id="enrolling-new-hypervisors">
<span id="id1"></span><h2>Enrolling New Hypervisors<a class="headerlink" href="#enrolling-new-hypervisors" title="Permalink to this heading">¶</a></h2>
<p>New hypervisors can be added to the Bifrost inventory by using its discovery
capabilities. Assuming that new hypervisors have IPMI enabled and are
configured to network boot on the provisioning network, the following commands
will instruct them to PXE boot. The nodes will boot on the Ironic Python Agent
kernel and ramdisk, which is configured to extract hardware information and
send it to Bifrost. Note that IPMI credentials can be found in the encrypted
file located at <code class="docutils literal notranslate"><span class="pre">${KAYOBE_CONFIG_PATH}/secrets.yml</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">bifrost# ipmitool -I lanplus -U admin -H comp0-ipmi chassis bootdev pxe</span>
</pre></div>
</div>
<p>If node is are off, power them on:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">bifrost# ipmitool -I lanplus -U admin -H comp0-ipmi power on</span>
</pre></div>
</div>
<p>If nodes is on, reset them:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">bifrost# ipmitool -I lanplus -U admin -H comp0-ipmi power reset</span>
</pre></div>
</div>
<p>Once node have booted and have completed introspection, they should be visible
in Bifrost:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">bifrost# baremetal node list --provision-state enroll</span>
<span class="go">+--------------------------------------+-----------------------+---------------+-------------+--------------------+-------------+</span>
<span class="go">| UUID                                 | Name                  | Instance UUID | Power State | Provisioning State | Maintenance |</span>
<span class="go">+--------------------------------------+-----------------------+---------------+-------------+--------------------+-------------+</span>
<span class="go">| da0c61af-b411-41b9-8909-df2509f2059b | comp0 | None          | power off   | enroll             | False       |</span>
<span class="go">+--------------------------------------+-----------------------+---------------+-------------+--------------------+-------------+</span>
</pre></div>
</div>
<p>After editing <code class="docutils literal notranslate"><span class="pre">${KAYOBE_CONFIG_PATH}/overcloud.yml</span></code> to add these new hosts to
the correct groups, import them in Kayobe’s inventory with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kayobe# kayobe overcloud inventory discover</span>
</pre></div>
</div>
<p>We can then provision and configure them:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kayobe# kayobe overcloud provision --limit comp0</span>
<span class="go">kayobe# kayobe overcloud host configure --limit comp0 --kolla-limit comp0</span>
<span class="go">kayobe# kayobe overcloud service deploy --limit comp0 --kolla-limit comp0</span>
</pre></div>
</div>
</section>
<section id="replacing-a-failing-hypervisor">
<h2>Replacing a Failing Hypervisor<a class="headerlink" href="#replacing-a-failing-hypervisor" title="Permalink to this heading">¶</a></h2>
<p>To replace a failing hypervisor, proceed as follows:</p>
<ul class="simple">
<li><p><a class="reference internal" href="operations_and_monitoring.html#taking-a-hypervisor-out-of-service"><span class="std std-ref">Disable the hypervisor to avoid scheduling any new instance on it</span></a></p></li>
<li><p><a class="reference internal" href="#evacuating-all-instances"><span class="std std-ref">Evacuate all instances</span></a></p></li>
<li><p><a class="reference internal" href="#set-bifrost-maintenance-mode"><span class="std std-ref">Set the node to maintenance mode in Bifrost</span></a></p></li>
<li><p>Physically fix or replace the node</p></li>
<li><p>It may be necessary to reinspect the node if hardware was changed (this will require deprovisioning and reprovisioning)</p></li>
<li><p>If the node was replaced or reprovisioned, follow <a class="reference internal" href="#enrolling-new-hypervisors"><span class="std std-ref">Enrolling New Hypervisors</span></a></p></li>
</ul>
<p>To deprovision an existing hypervisor, run:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kayobe# kayobe overcloud deprovision --limit comp0</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Always use <code class="docutils literal notranslate"><span class="pre">--limit</span></code> with <code class="docutils literal notranslate"><span class="pre">kayobe</span> <span class="pre">overcloud</span> <span class="pre">deprovision</span></code> on a production
system. Running this command without a limit will deprovision all overcloud
hosts.</p>
</div>
</section>
<section id="evacuating-all-instances">
<span id="id2"></span><h2>Evacuating all instances<a class="headerlink" href="#evacuating-all-instances" title="Permalink to this heading">¶</a></h2>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">admin# nova host-evacuate-live comp0</span>
</pre></div>
</div>
<p>You should now check the status of all the instances that were running on that
hypervisor. They should all show the status ACTIVE. This can be verified with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">admin# openstack server show &lt;instance uuid&gt;</span>
</pre></div>
</div>
<section id="troubleshooting">
<h3>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this heading">¶</a></h3>
<section id="servers-that-have-been-shut-down">
<h4>Servers that have been shut down<a class="headerlink" href="#servers-that-have-been-shut-down" title="Permalink to this heading">¶</a></h4>
<p>If there are any instances that are SHUTOFF they won’t be migrated, but you can
use <code class="docutils literal notranslate"><span class="pre">nova</span> <span class="pre">host-servers-migrate</span></code> for them once the live migration is finished.</p>
<p>Also if a VM does heavy memory access, it may take ages to migrate (Nova tries
to incrementally increase the expected downtime, but is quite conservative).
You can use <code class="docutils literal notranslate"><span class="pre">nova</span> <span class="pre">live-migration-force-complete</span> <span class="pre">&lt;instance_uuid&gt;</span>
<span class="pre">&lt;migration_id&gt;</span></code> to trigger the final move.</p>
<p>You get the migration ID via <code class="docutils literal notranslate"><span class="pre">nova</span> <span class="pre">server-migration-list</span> <span class="pre">&lt;instance_uuid&gt;</span></code>.</p>
<p>For more details see:
<a class="reference external" href="http://www.danplanet.com/blog/2016/03/03/evacuate-in-nova-one-command-to-confuse-us-all/">http://www.danplanet.com/blog/2016/03/03/evacuate-in-nova-one-command-to-confuse-us-all/</a></p>
</section>
<section id="flavors-have-changed">
<h4>Flavors have changed<a class="headerlink" href="#flavors-have-changed" title="Permalink to this heading">¶</a></h4>
<p>If the size of the flavors has changed, some instances will also fail to
migrate as the process needs manual confirmation. You can do this with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">openstack # openstack server resize confirm &lt;instance-uuid&gt;</span>
</pre></div>
</div>
<p>The symptom to look out for is that the server is showing a status of <code class="docutils literal notranslate"><span class="pre">VERIFY</span>
<span class="pre">RESIZE</span></code> as shown in this snippet of <code class="docutils literal notranslate"><span class="pre">openstack</span> <span class="pre">server</span> <span class="pre">show</span> <span class="pre">&lt;instance-uuid&gt;</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">| status | VERIFY_RESIZE |</span>
</pre></div>
</div>
</section>
</section>
<section id="set-maintenance-mode-on-a-node-in-bifrost">
<span id="set-bifrost-maintenance-mode"></span><h3>Set maintenance mode on a node in Bifrost<a class="headerlink" href="#set-maintenance-mode-on-a-node-in-bifrost" title="Permalink to this heading">¶</a></h3>
<p>For example, to put <code class="docutils literal notranslate"><span class="pre">comp0</span></code> into maintenance:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">seed# docker exec -it bifrost_deploy /bin/bash</span>
<span class="gp gp-VirtualEnv">(bifrost-deploy)</span><span class="gp">[root@seed bifrost-base]# </span><span class="nv">OS_CLOUD</span><span class="o">=</span>bifrost<span class="w"> </span>baremetal<span class="w"> </span>node<span class="w"> </span>maintenance<span class="w"> </span><span class="nb">set</span><span class="w"> </span>comp0
</pre></div>
</div>
</section>
<section id="unset-maintenance-mode-on-a-node-in-bifrost">
<span id="unset-bifrost-maintenance-mode"></span><h3>Unset maintenance mode on a node in Bifrost<a class="headerlink" href="#unset-maintenance-mode-on-a-node-in-bifrost" title="Permalink to this heading">¶</a></h3>
<p>For example, to take <code class="docutils literal notranslate"><span class="pre">comp0</span></code> out of maintenance:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">seed# docker exec -it bifrost_deploy /bin/bash</span>
<span class="gp gp-VirtualEnv">(bifrost-deploy)</span><span class="gp">[root@seed bifrost-base]# </span><span class="nv">OS_CLOUD</span><span class="o">=</span>bifrost<span class="w"> </span>baremetal<span class="w"> </span>node<span class="w"> </span>maintenance<span class="w"> </span><span class="nb">unset</span><span class="w"> </span>comp0
</pre></div>
</div>
</section>
</section>
<section id="detect-hardware-differences-with-cardiff">
<h2>Detect hardware differences with cardiff<a class="headerlink" href="#detect-hardware-differences-with-cardiff" title="Permalink to this heading">¶</a></h2>
<p>Hardware information captured during the Ironic introspection process can be
analysed to detect hardware differences, such as mismatches in firmware
versions or missing storage devices. The cardiff tool can be used for this
purpose. It was developed as part of the <a class="reference external" href="https://pypi.org/project/hardware/">Python hardware package</a>, but was removed from release 0.25. The
<a class="reference external" href="https://github.com/stackhpc/mungetout/">mungetout utility</a> can be used to
convert Ironic introspection data into a format that can be fed to cardiff.</p>
<p>The following steps are used to install cardiff and mungetout:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kayobe# virtualenv ~/kayobe-env/venvs/cardiff</span>
<span class="go">kayobe# source ~/kayobe-env/venvs/cardiff/bin/activate</span>
<span class="go">kayobe# pip install -U pip</span>
<span class="go">kayobe# pip install git+https://github.com/stackhpc/mungetout.git@feature/kayobe-introspection-save</span>
<span class="go">kayobe# pip install &#39;hardware==0.24&#39;</span>
</pre></div>
</div>
<p>Extract introspection data from Bifrost with Kayobe. JSON files will be created
into <code class="docutils literal notranslate"><span class="pre">${KAYOBE_CONFIG_PATH}/overcloud-introspection-data</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kayobe# source ~/kayobe-env/venvs/kayobe/bin/activate</span>
<span class="go">kayobe# source ~/kayobe-env/src/kayobe-config/kayobe-env</span>
<span class="go">kayobe# kayobe overcloud introspection data save</span>
</pre></div>
</div>
<p>The cardiff utility can only work if the <code class="docutils literal notranslate"><span class="pre">extra-hardware</span></code> collector was used,
which populates a <code class="docutils literal notranslate"><span class="pre">data</span></code> key in each node JSON file. Remove any that are
missing this key:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kayobe# for file in ~/kayobe-env/src/kayobe-config/overcloud-introspection-data/*; do if [[ $(jq .data $file) == &#39;null&#39; ]]; then rm $file; fi; done</span>
</pre></div>
</div>
<p>Cardiff identifies each unique system by its serial number. However, some
high-density multi-node systems may report the same serial number for multiple
systems (this has been seen on Supermicro hardware). The following script will
replace the serial number used by Cardiff by the node name captured by LLDP on
the first network interface. If this node name is missing, it will append a
short UUID string to the end of the serial number.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">uuid</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;r+&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">node</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>

    <span class="n">serial</span> <span class="o">=</span> <span class="n">node</span><span class="p">[</span><span class="s2">&quot;inventory&quot;</span><span class="p">][</span><span class="s2">&quot;system_vendor&quot;</span><span class="p">][</span><span class="s2">&quot;serial_number&quot;</span><span class="p">]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">new_serial</span> <span class="o">=</span> <span class="n">node</span><span class="p">[</span><span class="s2">&quot;all_interfaces&quot;</span><span class="p">][</span><span class="s2">&quot;eth0&quot;</span><span class="p">][</span><span class="s2">&quot;lldp_processed&quot;</span><span class="p">][</span><span class="s2">&quot;switch_port_description&quot;</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="n">new_serial</span> <span class="o">=</span> <span class="n">serial</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())[:</span><span class="mi">8</span><span class="p">]</span>

    <span class="n">new_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">node</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;system&quot;</span> <span class="ow">and</span> <span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;product&quot;</span> <span class="ow">and</span> <span class="n">e</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;serial&quot;</span><span class="p">:</span>
            <span class="n">new_data</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;product&quot;</span><span class="p">,</span> <span class="s2">&quot;serial&quot;</span><span class="p">,</span> <span class="n">new_serial</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
    <span class="n">node</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_data</span>

    <span class="n">f</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">node</span><span class="p">))</span>
    <span class="n">f</span><span class="o">.</span><span class="n">truncate</span><span class="p">()</span>
</pre></div>
</div>
<p>Apply this Python script on all generated JSON files:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kayobe# for file in ~/src/kayobe-config/overcloud-introspection-data/*; do python update-serial.py $file; done</span>
</pre></div>
</div>
<p>Convert files into the format supported by cardiff:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">source ~/kayobe-env/venvs/cardiff/bin/activate</span>
<span class="go">mkdir -p ~/kayobe-env/cardiff-workspace</span>
<span class="go">rm -rf ~/kayobe-env/cardiff-workspace/extra*</span>
<span class="go">cd ~/kayobe-env/cardiff-workspace/</span>
<span class="go">m2-extract ~/kayobe-env/src/kayobe-config/overcloud-introspection-data/*.json</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">m2-extract</span></code> utility needs to work in an empty folder. Delete the
<code class="docutils literal notranslate"><span class="pre">extra-hardware</span></code>, <code class="docutils literal notranslate"><span class="pre">extra-hardware-filtered</span></code> and <code class="docutils literal notranslate"><span class="pre">extra-hardware-json</span></code>
folders before executing it again.</p>
</div>
<p>We are now ready to compare node hardware. The following command will compare
all known nodes, which may include multiple generations of hardware. Replace
<code class="docutils literal notranslate"><span class="pre">*.eval</span></code> by a stricter globbing expression or by a list of files to compare a
smaller group.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">hardware-cardiff -I ipmi -p &#39;extra-hardware/*.eval&#39;</span>
</pre></div>
</div>
<p>Since the output can be verbose, it is recommended to pipe it to a terminal
pager or redirect it to a file. Cardiff will display groups of identical nodes
based on various hardware characteristics, such as system model, BIOS version,
CPU or network interface information, or benchmark results gathered by the
<code class="docutils literal notranslate"><span class="pre">extra-hardware</span></code> collector during the initial introspection process.</p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">OpenStack Administration Guide</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_with_openstack.html">Working with OpenStack</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_with_kayobe.html">Working with Kayobe</a></li>
<li class="toctree-l1"><a class="reference internal" href="physical_network.html">Physical network</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hardware Inventory Management</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#reconfiguring-control-plane-hardware">Reconfiguring Control Plane Hardware</a></li>
<li class="toctree-l2"><a class="reference internal" href="#enrolling-new-hypervisors">Enrolling New Hypervisors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#replacing-a-failing-hypervisor">Replacing a Failing Hypervisor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#evacuating-all-instances">Evacuating all instances</a></li>
<li class="toctree-l2"><a class="reference internal" href="#detect-hardware-differences-with-cardiff">Detect hardware differences with cardiff</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ceph_storage.html">Ceph Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="managing_users_and_projects.html">Managing Users and Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="operations_and_monitoring.html">Operations and Monitoring</a></li>
<li class="toctree-l1"><a class="reference internal" href="wazuh.html">Wazuh Security Platform</a></li>
<li class="toctree-l1"><a class="reference internal" href="customising_deployment.html">Customising the OpenStack Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpus_in_openstack.html">Support for GPUs in OpenStack</a></li>
<li class="toctree-l1"><a class="reference internal" href="baremetal_management.html">Bare Metal Compute Hardware Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="rally_and_tempest.html">Verifying the Cloud with Rally and Tempest</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="physical_network.html" title="previous chapter">Physical network</a></li>
      <li>Next: <a href="ceph_storage.html" title="next chapter">Ceph Storage</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020-2023, StackHPC Ltd.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/hardware_inventory_management.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>